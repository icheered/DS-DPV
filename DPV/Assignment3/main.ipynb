{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # needed for most operation\n",
    "import numpy as np # needed for some array operations\n",
    "from sqlalchemy import create_engine, types # needed for DB connection\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Load the data from CSV files\n",
    "main_df = pd.read_csv('inputdata/main.csv', delimiter=';', encoding=\"ISO-8859-1\")\n",
    "managers_df = pd.read_csv('inputdata/managers.csv', delimiter=';', encoding=\"ISO-8859-1\")\n",
    "returns_df = pd.read_csv('inputdata/returns.csv', delimiter=';', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'Late' column\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "main_df['Order Date'] = main_df['Order Date'].apply(lambda x: datetime.strptime(x, '%d/%m/%y'))\n",
    "main_df['Ship Date'] = main_df['Ship Date'].apply(lambda x: datetime.strptime(x, '%d/%m/%y'))\n",
    "\n",
    "# Calculate the number of days late and create the \"Late\" column\n",
    "main_df['Late'] = main_df.apply(lambda x: 'Late' if (x['Ship Date'] - x['Order Date']).days > 2 else 'NotLate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the data from the three CSV files to create a single DataFrame\n",
    "merged_df = main_df.merge(managers_df, on='Region')\n",
    "merged_df = merged_df.merge(returns_df, on='Order ID')\n",
    "\n",
    "# Replace commas with periods\n",
    "merged_df['Sales'] = merged_df['Sales'].str.replace(',', '.').astype(float)\n",
    "merged_df['Unit Price'] = merged_df['Unit Price'].str.replace(',', '.').astype(float)\n",
    "merged_df['Profit'] = merged_df['Profit'].str.replace(',', '.').astype(float)\n",
    "merged_df['Shipping Cost'] = merged_df['Shipping Cost'].str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the \"ReturnStatus\" dimension table\n",
    "return_status_df = pd.DataFrame({\n",
    "    'returnstatusid': [0, 1],\n",
    "    'returnvalue': ['NotReturned', 'Returned']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the \"product\" dimension table\n",
    "product_df = merged_df[['Product Name', 'Product Category', 'Product Sub-Category']].drop_duplicates().reset_index(drop=True).reset_index().rename(columns={'index': 'productid'})\n",
    "product_df['productid'] += 1\n",
    "\n",
    "# Create the \"customers\" dimension table\n",
    "customers_df = merged_df[['Customer Name', 'Province', 'Region', 'Customer Segment']].drop_duplicates().reset_index(drop=True).reset_index().rename(columns={'index': 'customerid'})\n",
    "customers_df['customerid'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the \"sales\" fact table\n",
    "sales_df = merged_df.merge(product_df, on=['Product Name', 'Product Category', 'Product Sub-Category'])\n",
    "sales_df = sales_df.merge(customers_df, on=['Customer Name', 'Province', 'Region', 'Customer Segment'])\n",
    "sales_df = sales_df.merge(return_status_df, left_on='Status', right_on='returnvalue')\n",
    "sales_df = sales_df.rename(columns={\n",
    "    'Order Date': 'orderdate',\n",
    "    'Order Quantity': 'orderquantity',\n",
    "    'Sales': 'sales',\n",
    "    'Unit Price': 'unitprice',\n",
    "    'Profit': 'profit',\n",
    "    'Shipping Cost': 'shippingcost',\n",
    "    'Late': 'late'\n",
    "}).drop(['Product Name', 'Product Category', 'Product Sub-Category', 'Customer Name', 'Province', 'Region', 'Customer Segment', 'Status'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the resulting tables to CSV files in an output directory (optional)\n",
    "# sales_df.to_csv('output/sales.csv', index=False)\n",
    "# product_df.to_csv('output/product.csv', index=False)\n",
    "# customers_df.to_csv('output/customers.csv', index=False)\n",
    "# return_status_df.to_csv('output/return_status.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_35501/1406380526.py\", line 23, in <module>\n",
      "    sales_df.to_sql('sales', engine,schema='ass3', index=False, if_exists='replace', dtype=column_data_types)\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib64/python3.10/site-packages/pandas/core/generic.py\", line 2872, in to_sql\n",
      "    method : {None, 'multi', callable}, optional\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib64/python3.10/site-packages/pandas/io/sql.py\", line 708, in to_sql\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib64/python3.10/site-packages/pandas/io/sql.py\", line 788, in pandasSQL_builder\n",
      "    index_label=None,\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib64/python3.10/site-packages/pandas/io/sql.py\", line 1410, in __init__\n",
      "    index_col: str | list[str] | None = None,\n",
      "TypeError: MetaData.__init__() got multiple values for argument 'schema'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/tjbakker/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Connect to database\n",
    "driver='postgresql'\n",
    "username='dab_ds22232a_46'\n",
    "dbname=username # it is the same as the username\n",
    "password='5wQ5aeeIp3Xaobd6'\n",
    "server='bronto.ewi.utwente.nl'\n",
    "port='5432'\n",
    "\n",
    "# Creating the connection pool for SQLalchemy\n",
    "engine = create_engine(f'{driver}://{username}:{password}@{server}:{port}/{dbname}')\n",
    "column_data_types = {\n",
    "    'product_id': types.INTEGER,\n",
    "    'customer_id': types.INTEGER,\n",
    "    'orderdate': types.DATE,\n",
    "    'returnstatusid': types.INTEGER,\n",
    "    'late': types.TEXT,\n",
    "    'sales': types.DOUBLE_PRECISION,\n",
    "    'orderquantity': types.DOUBLE_PRECISION,\n",
    "    'unitprice': types.DOUBLE_PRECISION,\n",
    "    'profit': types.DOUBLE_PRECISION,\n",
    "    'shippingcost': types.DOUBLE_PRECISION,\n",
    "}\n",
    "sales_df.to_sql('sales', engine,schema='ass3', index=False, if_exists='replace', dtype=column_data_types)\n",
    "product_df.to_sql('product', engine,schema='ass3', index=False, if_exists='replace')\n",
    "customers_df.to_sql('customers', engine,schema='ass3', index=False, if_exists='replace')\n",
    "return_status_df.to_sql('return_status', engine,schema='ass3', index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sales',), ('product',), ('customers',), ('return_status',)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MetaData.__init__() got multiple values for argument 'schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m result \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39mexecute(text(\u001b[39m\"\"\"\u001b[39m\u001b[39mSELECT table_name FROM information_schema.tables\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[39m                                where table_schema=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mass3\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\"\"\u001b[39m))\u001b[39m.\u001b[39mfetchall() \u001b[39m## to get the tables from schema ass2\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(result)\n\u001b[0;32m---> 17\u001b[0m pd\u001b[39m.\u001b[39;49mread_sql_table(\u001b[39m'\u001b[39;49m\u001b[39msales\u001b[39;49m\u001b[39m'\u001b[39;49m, connection,schema\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mass3\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39minfo()\n\u001b[1;32m     18\u001b[0m pd\u001b[39m.\u001b[39mread_sql_table(\u001b[39m'\u001b[39m\u001b[39mproduct\u001b[39m\u001b[39m'\u001b[39m, connection,schema\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mass3\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39minfo()\n\u001b[1;32m     19\u001b[0m pd\u001b[39m.\u001b[39mread_sql_table(\u001b[39m'\u001b[39m\u001b[39mcustomer\u001b[39m\u001b[39m'\u001b[39m, connection,schema\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mass3\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39minfo()\n",
      "File \u001b[0;32m~/Documents/University/Master/Module3/DataScience/DS/DPV/.venv/lib64/python3.10/site-packages/pandas/io/sql.py:318\u001b[0m, in \u001b[0;36mread_sql_table\u001b[0;34m(table_name, con, schema, index_col, coerce_float, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mschema\u001b[39;00m \u001b[39mimport\u001b[39;00m MetaData\n\u001b[0;32m--> 318\u001b[0m meta \u001b[39m=\u001b[39m MetaData(con, schema\u001b[39m=\u001b[39;49mschema)\n\u001b[1;32m    319\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     meta\u001b[39m.\u001b[39mreflect(only\u001b[39m=\u001b[39m[table_name], views\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: MetaData.__init__() got multiple values for argument 'schema'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text # needed for DB connection\n",
    "import pandas as pd # needed for most operation\n",
    "\n",
    "driver='postgresql'\n",
    "username='dab_ds22232a_46'\n",
    "dbname=username # it is the same as the username\n",
    "password='5wQ5aeeIp3Xaobd6'\n",
    "server='bronto.ewi.utwente.nl'\n",
    "port='5432'\n",
    "engine = create_engine(f'{driver}://{username}:{password}@{server}:{port}/{dbname}')\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"\"\"SELECT table_name FROM information_schema.tables\n",
    "                                    where table_schema='ass3'\"\"\")).fetchall() ## to get the tables from schema ass2\n",
    "    print(result)\n",
    "\n",
    "    pd.read_sql_table('sales', connection,schema='ass3').info()\n",
    "    pd.read_sql_table('product', connection,schema='ass3').info()\n",
    "    pd.read_sql_table('customer', connection,schema='ass3').info()\n",
    "    pd.read_sql_table('returnstatus', connection,schema='ass3').info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3dc5a15a2f019f38574d8e8c35223ba2a55bc1e91b1f466f8db45323037b26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
